{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f3f5a2a",
   "metadata": {},
   "source": [
    "# Assignment 02: Supervised Learning\n",
    "\n",
    "This assignment explores **supervised learning** through the lens of two classification algorithms: **Support Vector Machines (SVM)** and **Multi-Layer Perceptrons (MLP)**. You will apply both models to datasets that highlight their strengths and limitations, use grid search with cross-validation to find optimal hyperparameters, and report results using standard classification metrics.\n",
    "\n",
    "### Hand-in Instructions\n",
    "\n",
    "Name your files using the pattern `{group_number}_assignment_02` (e.g., `g03_assignment_02.ipynb`).\n",
    "\n",
    "Submit the following two files:\n",
    "\n",
    "1. **`.ipynb`** — The completed notebook with all outputs saved\n",
    "2. **`.pdf`** — Exported PDF version (see [README: Exporting Notebooks to HTML and PDF](../../README.md#exporting-notebooks-to-html-and-pdf))\n",
    "\n",
    "Both files must be fully self-contained and ready to read without running any cells.\n",
    "\n",
    "### Overview\n",
    "\n",
    "| Task  | Topic                           | Points  |\n",
    "| ----- | ------------------------------- | ------- |\n",
    "| **1** | **Dry Bean Exploration**        |         |\n",
    "| 1.1   | Class balance                   | 5       |\n",
    "| 1.2   | Feature scales                  | 5       |\n",
    "| 1.3   | Feature distributions           | 5       |\n",
    "| **2** | **Dry Bean Classification**     |         |\n",
    "| 2.1   | SVM grid search                 | 0       |\n",
    "| 2.2   | SVM evaluation                  | 5       |\n",
    "| 2.3   | MLP grid search                 | 15      |\n",
    "| 2.4   | MLP evaluation                  | 15      |\n",
    "| 2.5   | Compare SVM vs MLP              | 10      |\n",
    "| **3** | **Checkerboard Classification** |         |\n",
    "| 3.1   | Visualize Checkerboard          | 5       |\n",
    "| 3.2   | SVM classification              | 10      |\n",
    "| 3.3   | MLP classification              | 10      |\n",
    "| 3.4   | Compare decision boundaries     | 15      |\n",
    "|       | **Total**                       | **100** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a07b422",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f88b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from assignment_utils import (\n",
    "    generate_checkerboard,\n",
    "    load_dry_bean,\n",
    "    plot_decision_boundary,\n",
    "    plot_grid_search_heatmap,\n",
    "    plot_roc_curves,\n",
    "    print_evaluation_metrics,\n",
    "    print_grid_search_results,\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb20d977",
   "metadata": {},
   "source": [
    "## Task 1: Setup & Data Exploration\n",
    "\n",
    "In this section, you will load and explore the **Dry Bean Dataset**, a real-world multi-class classification problem from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/602/dry+bean+dataset). Images of 7 types of dry beans were captured, and 16 geometric features were extracted. Run the cell below to load the data.\n",
    "\n",
    "#### Feature Descriptions\n",
    "\n",
    "The 16 features are derived from image segmentation and morphological analysis (Köklü & Özkan, 2020). Let $A$ = Area, $P$ = Perimeter, $L$ = MajorAxisLength, $l$ = MinorAxisLength, $C$ = ConvexArea, and $E_d$ = EquivDiameter.\n",
    "\n",
    "| Feature             | Description                                               | Formula/Definition       |\n",
    "| ------------------- | --------------------------------------------------------- | ------------------------ |\n",
    "| **Area**            | Number of pixels within the bean boundary                 | $A$ (pixels)             |\n",
    "| **Perimeter**       | Length of the bean's border                               | $P$ (pixels)             |\n",
    "| **MajorAxisLength** | Length of the longest line through the bean               | $L$                      |\n",
    "| **MinorAxisLength** | Longest line perpendicular to the major axis              | $l$                      |\n",
    "| **AspectRatio**\\*   | Ratio of major to minor axis                              | $K = L / l$              |\n",
    "| **Eccentricity**    | Eccentricity of an ellipse with same moments              | $\\sqrt{1 - (l/L)^2}$     |\n",
    "| **ConvexArea**      | Pixels in the smallest convex polygon containing the bean | $C$ (pixels)             |\n",
    "| **EquivDiameter**   | Diameter of a circle with the same area                   | $E_d = \\sqrt{4A/\\pi}$    |\n",
    "| **Extent**          | Ratio of bean area to bounding box area                   | $A / (\\text{bbox area})$ |\n",
    "| **Solidity**        | Ratio of bean area to convex hull area (convexity)        | $A / C$                  |\n",
    "| **Roundness**       | Circularity measure                                       | $4\\pi A / P^2$           |\n",
    "| **Compactness**     | Roundness measure using equivalent diameter               | $E_d / L$                |\n",
    "| **ShapeFactor1**    | Length-to-area ratio                                      | $L / A$                  |\n",
    "| **ShapeFactor2**    | Width-to-area ratio                                       | $l / A$                  |\n",
    "| **ShapeFactor3**    | Ratio of area to circle with diameter $L$                 | $4A / (\\pi L^2)$         |\n",
    "| **ShapeFactor4**    | Ratio of area to ellipse with axes $L$, $l$               | $4A / (\\pi L l)$         |\n",
    "\n",
    "\\*Note: This feature is misspelled as \"AspectRation\" in the original dataset.\n",
    "\n",
    "**Target:** 7 bean classes — Seker, Barbunya, Bombay, Cali, Dermason, Horoz, Sira\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994ddd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dry Bean dataset\n",
    "X_bean, y_bean, feature_names_bean, class_names_bean = load_dry_bean()\n",
    "\n",
    "# Create DataFrame\n",
    "df_bean = pd.DataFrame(X_bean, columns=feature_names_bean)\n",
    "df_bean[\"Class\"] = [class_names_bean[i] for i in y_bean]\n",
    "\n",
    "print(f\"Shape: {df_bean.shape}\")\n",
    "print(f\"Classes: {class_names_bean}\")\n",
    "df_bean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca378467",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bean[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9a0e57",
   "metadata": {},
   "source": [
    "### Task 1.1 Class Balance\n",
    "\n",
    "- Task: Visualize the distribution of bean classes and analyze class imbalance.\n",
    "- Points: 5\n",
    "- Expectations: Bar chart showing class counts. 2-3 sentences discussing: (1) whether the dataset is balanced or imbalanced, (2) the ratio between the largest and smallest classes, and (3) potential implications for classifier training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0875c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: Use sns.countplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded39664",
   "metadata": {},
   "source": [
    "#### Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf162fd",
   "metadata": {},
   "source": [
    "### Task 1.2 Feature Scales\n",
    "\n",
    "- Task: Analyze the range of values across all 16 features to determine if scaling is needed.\n",
    "- Points: 5\n",
    "- Expectations: Visualization comparing feature ranges. 1-2 sentences on whether scaling is required and why.\n",
    "- Hint: Use `plt.yscale(\"log\")` to show features with very different magnitudes on the same plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a5629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute max-min range for each feature\n",
    "\n",
    "# Plot the ranges per feature with sns.barplot()\n",
    "\n",
    "# Use plt.yscale(\"log\") for better visualization of scale differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797ad9e5",
   "metadata": {},
   "source": [
    "### Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e5680",
   "metadata": {},
   "source": [
    "### Task 1.3 Feature Distributions by Class\n",
    "\n",
    "- Task: Explore how feature values differ across bean classes.\n",
    "- Points: 5\n",
    "- Expectations: Create overlapping histograms (or density plots) for all 16 features, colored by class (already done). Identify two features that, when combined, would provide good class separation and briefly justify your selection (2-3 sentences).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f2accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 4, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feat in zip(axes, feature_names_bean):\n",
    "    sns.histplot(\n",
    "        data=df_bean,\n",
    "        x=feat,\n",
    "        hue=\"Class\",\n",
    "        stat=\"density\",\n",
    "        common_norm=False,\n",
    "        alpha=0.5,\n",
    "        ax=ax,\n",
    "        legend=False,\n",
    "    )\n",
    "    ax.set_title(feat)\n",
    "    ax.set_xlabel(\"Feature Value\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "\n",
    "# Add shared legend\n",
    "handles, labels = [], []\n",
    "for bean_class in sorted(df_bean[\"Class\"].unique()):\n",
    "    handles.append(\n",
    "        plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            color=sns.color_palette()[\n",
    "                sorted(df_bean[\"Class\"].unique()).index(bean_class)\n",
    "            ],\n",
    "            lw=4,\n",
    "        )\n",
    "    )\n",
    "    labels.append(bean_class)\n",
    "fig.legend(handles, labels, loc=\"center right\", bbox_to_anchor=(1.08, 0.5), fontsize=10)\n",
    "\n",
    "plt.suptitle(\"Dry Bean Feature Distributions by Class\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f717bf3",
   "metadata": {},
   "source": [
    "#### Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4289eb40",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2: Dry Bean Classification\n",
    "\n",
    "Now you will apply both SVM and MLP to the Dry Bean dataset. Since this is a multi-class problem with 7 classes, both algorithms should be able to achieve good performance with proper hyperparameter tuning.\n",
    "\n",
    "First, let's prepare the data by splitting into train and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64218621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation folds used for all grid searches\n",
    "CV_FOLDS = 5\n",
    "\n",
    "# Train/test split for Dry Bean (80/20)\n",
    "X_bean_train, X_bean_test, y_bean_train, y_bean_test = train_test_split(\n",
    "    X_bean, y_bean, test_size=0.2, random_state=42, stratify=y_bean\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_bean_train)} samples\")\n",
    "print(f\"Test set: {len(X_bean_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40919bb",
   "metadata": {},
   "source": [
    "### Task 2.1 SVM Grid Search (Dry Bean)\n",
    "\n",
    "**Note:** This is already answered for you so that you see how we can do grid search.\n",
    "\n",
    "- Task: Use GridSearchCV to find optimal hyperparameters for an SVM classifier on the Dry Bean dataset. Use a Pipeline with StandardScaler and SVC (RBF kernel). Search over at least: `C` (3+ values) and `gamma` (3+ values).\n",
    "- Points: 0\n",
    "- Expectations: Working grid search code. Report best parameters and best CV score using `print_grid_search_results()`. Include a heatmap of CV scores for C vs gamma using `plot_grid_search_heatmap()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c6a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Pipeline: StandardScaler + SVC (RBF kernel)\n",
    "svm_pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(random_state=42, kernel=\"rbf\", probability=True)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Hyperparameter grid\n",
    "svm_param_grid = {\n",
    "    \"svc__C\": [0.1, 1, 10, 100],\n",
    "    \"svc__gamma\": [0.001, 0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "svm_grid = GridSearchCV(\n",
    "    svm_pipe, svm_param_grid, cv=CV_FOLDS, scoring=\"accuracy\", n_jobs=-1, refit=True\n",
    ")\n",
    "svm_grid.fit(X_bean_train, y_bean_train)\n",
    "\n",
    "print_grid_search_results(svm_grid, \"SVM (Dry Bean)\")\n",
    "\n",
    "# Heatmap of CV scores: C vs gamma\n",
    "plot_grid_search_heatmap(\n",
    "    svm_grid,\n",
    "    param_x=\"svc__C\",\n",
    "    param_y=\"svc__gamma\",\n",
    "    title=\"SVM CV Accuracy — C vs gamma\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8e7163",
   "metadata": {},
   "source": [
    "### Task 2.2 SVM Evaluation (Dry Bean)\n",
    "\n",
    "**Note:** The code part (1-3) of this task is answered for you so you see an example of how you can use helpers to evaluate the results.\n",
    "\n",
    "- Task: Evaluate your best SVM model on the test set.\n",
    "- Points: 5\n",
    "- Expectations:\n",
    "  1. Evaluation metrics using `print_evaluation_metrics()`\n",
    "  2. Confusion matrix using `ConfusionMatrixDisplay` with class labels\n",
    "  3. ROC curve with AUC score using `plot_roc_curves()`\n",
    "  4. Written interpretation identifying which bean types are most often confused and whether this aligns with the feature overlap you observed in Task 1.3 (1 paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e0b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best SVM model\n",
    "best_svm = svm_grid.best_estimator_\n",
    "y_pred_svm = best_svm.predict(X_bean_test)\n",
    "\n",
    "# Precision, Recall, F1\n",
    "svm_report = print_evaluation_metrics(y_bean_test, y_pred_svm, \"SVM (Dry Bean)\")\n",
    "\n",
    "# Confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_bean_test, y_pred_svm, display_labels=class_names_bean, ax=ax, cmap=\"Blues\"\n",
    ")\n",
    "ax.set_title(\"SVM Confusion Matrix — Dry Bean\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ROC curve (One-vs-Rest)\n",
    "y_proba_svm = best_svm.predict_proba(X_bean_test)\n",
    "roc_auc_svm, _ = plot_roc_curves(\n",
    "    y_bean_test,\n",
    "    y_proba_svm,\n",
    "    class_names=class_names_bean,\n",
    "    title=\"SVM ROC Curves — Dry Bean (One-vs-Rest)\",\n",
    ")\n",
    "plt.show()\n",
    "print(f\"ROC-AUC (macro, OvR): {roc_auc_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff3f136",
   "metadata": {},
   "source": [
    "#### Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b376850",
   "metadata": {},
   "source": [
    "### Task 2.3 MLP Grid Search (Dry Bean)\n",
    "\n",
    "- Task: Use GridSearchCV to find optimal hyperparameters for an MLP classifier on the Dry Bean dataset. Use a Pipeline with StandardScaler and MLPClassifier (relu activation). Search over at least: `hidden_layer_sizes` (3+ architectures) and `learning_rate_init` (2+ values).\n",
    "- Points: 15\n",
    "- Expectations: Working grid search code. Report best parameters and best CV score using `print_grid_search_results()`. Include a heatmap of CV scores for hidden_layer_sizes vs learning_rate_init using `plot_grid_search_heatmap()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8502a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Pipeline: StandardScaler + MLPClassifier (relu activation)\n",
    "\n",
    "# Hyperparameter grid\n",
    "\n",
    "# Grid search with cross-validation\n",
    "\n",
    "# Plot heatmap of CV scores: hidden_layer_sizes vs learning_rate_init\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8982c22",
   "metadata": {},
   "source": [
    "### Task 2.4 MLP Evaluation (Dry Bean)\n",
    "\n",
    "- Task: Evaluate your best MLP model on the test set.\n",
    "- Points: 15\n",
    "- Expectations:\n",
    "  1. Evaluation metrics using `print_evaluation_metrics()`\n",
    "  2. Confusion matrix using `ConfusionMatrixDisplay` with class labels\n",
    "  3. ROC curve with AUC score using `plot_roc_curves()`\n",
    "  4. Written interpretation identifying which bean types are most often confused (1 paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7683a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best MLP model\n",
    "\n",
    "# Precision, Recall, F1\n",
    "\n",
    "# Confusion matrix\n",
    "\n",
    "# ROC curve (One-vs-Rest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443396da",
   "metadata": {},
   "source": [
    "#### Answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474cc5b7",
   "metadata": {},
   "source": [
    "### Task 2.5 Compare SVM vs MLP (Dry Bean)\n",
    "\n",
    "- Task: Compare the performance of your best SVM and best MLP on the Dry Bean dataset. Fill in the comparison table below.\n",
    "- Points: 10\n",
    "- Expectations: Completed comparison table. Recommendation with justification (1 paragraph). Identify which metrics in the table account for the class imbalance you observed in Task 1.1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c898bc26",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "\n",
    "| Metric            | SVM | MLP |\n",
    "| ----------------- | --- | --- |\n",
    "| Test Accuracy     |     |     |\n",
    "| Macro F1-Score    |     |     |\n",
    "| Weighted F1-Score |     |     |\n",
    "| ROC-AUC (macro)   |     |     |\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70861c60",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 3: Checkerboard Classification\n",
    "\n",
    "Now you will work with the **Checkerboard Dataset** — a synthetic 2D dataset designed to expose a fundamental limitation of kernel-based methods like SVM.\n",
    "\n",
    "**Checkerboard Dataset** (Synthetic): A 2D dataset where the plane is divided into a grid of squares with alternating class labels (like a chess board). This dataset challenges kernel-based methods because points that are spatially close can belong to different classes.\n",
    "\n",
    "First, let's generate and visualize the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e43547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Checkerboard dataset\n",
    "X_checker, y_checker = generate_checkerboard(\n",
    "    n_samples=2000, grid_size=6, noise=0.01, seed=42\n",
    ")\n",
    "\n",
    "# Create DataFrame\n",
    "df_checker = pd.DataFrame(X_checker, columns=[\"X\", \"Y\"])\n",
    "df_checker[\"Class\"] = y_checker\n",
    "\n",
    "print(f\"Shape: {df_checker.shape}\")\n",
    "df_checker.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67b3c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checker[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e2c8c0",
   "metadata": {},
   "source": [
    "### Task 3.1 Visualize Checkerboard\n",
    "\n",
    "- Task: Create a scatter plot of the Checkerboard dataset colored by class label.\n",
    "- Points: 5\n",
    "- Expectations: A 2D scatter plot clearly showing the checkerboard pattern. One sentence on what you observe about class separability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fc784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: Use plt.scatter with c=y_checker and cmap=\"bwr\" for red/blue classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b9edb",
   "metadata": {},
   "source": [
    "#### Answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d17ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split for Checkerboard (80/20)\n",
    "X_checker_train, X_checker_test, y_checker_train, y_checker_test = train_test_split(\n",
    "    X_checker, y_checker, test_size=0.2, random_state=42, stratify=y_checker\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_checker_train)} samples\")\n",
    "print(f\"Test set: {len(X_checker_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc8db53",
   "metadata": {},
   "source": [
    "### Task 3.2 SVM on Checkerboard\n",
    "\n",
    "- Task: Apply SVM with grid search to the Checkerboard dataset. Use a Pipeline with StandardScaler and SVC (RBF kernel). Search over `C` and `gamma`.\n",
    "- Points: 10\n",
    "- Expectations:\n",
    "  1. Pipeline with `StandardScaler` and `SVC` using `GridSearchCV`\n",
    "  2. Report best parameters using `print_grid_search_results()`\n",
    "  3. Evaluation metrics using `print_evaluation_metrics()`\n",
    "  4. Confusion matrix using `ConfusionMatrixDisplay`\n",
    "  5. ROC curve with AUC score using `plot_roc_curves()`\n",
    "  6. Decision boundary using `plot_decision_boundary()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb555fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Pipeline: StandardScaler + SVC (RBF kernel)\n",
    "\n",
    "# Hyperparameter grid\n",
    "\n",
    "# Grid search with cross-validation\n",
    "\n",
    "# Print grid search results\n",
    "\n",
    "# Evaluate on test set\n",
    "\n",
    "# Print evaluation metrics\n",
    "\n",
    "# Confusion matrix\n",
    "\n",
    "# ROC curve\n",
    "\n",
    "# Plot decision boundary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052c42b3",
   "metadata": {},
   "source": [
    "### Task 3.3 MLP on Checkerboard\n",
    "\n",
    "- Task: Apply MLP with grid search to the Checkerboard dataset. Use a Pipeline with StandardScaler and MLPClassifier (relu activation). Search over `hidden_layer_sizes` and `learning_rate_init`.\n",
    "- Points: 10\n",
    "- Expectations:\n",
    "  1. Pipeline with `StandardScaler` and `MLPClassifier` using `GridSearchCV`\n",
    "  2. Report best parameters using `print_grid_search_results()`\n",
    "  3. Evaluation metrics using `print_evaluation_metrics()`\n",
    "  4. Confusion matrix using `ConfusionMatrixDisplay`\n",
    "  5. ROC curve with AUC score using `plot_roc_curves()`\n",
    "  6. Decision boundary using `plot_decision_boundary()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d8178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Pipeline: StandardScaler + MLPClassifier (relu activation)\n",
    "\n",
    "# Hyperparameter grid\n",
    "\n",
    "# Grid search with cross-validation\n",
    "\n",
    "# Print grid search results\n",
    "\n",
    "# Evaluate on test set\n",
    "\n",
    "# Print evaluation metrics\n",
    "\n",
    "# Confusion matrix\n",
    "\n",
    "# ROC curve\n",
    "\n",
    "# Plot decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a710da5",
   "metadata": {},
   "source": [
    "### Task 3.4 Compare Decision Boundaries\n",
    "\n",
    "Compare the decision boundary plots and accuracy results from Tasks 3.2 and 3.3.\n",
    "\n",
    "- Task: Describe the decision boundaries and explain why MLP succeeds on the Checkerboard dataset.\n",
    "- Points: 15\n",
    "- Expectations:\n",
    "  1. Describe what you observe about each model's decision boundaries (1-2 sentences each)\n",
    "  2. Explain how MLP's architecture (hidden layers with ReLU activations) enables it to learn the checkerboard pattern (1 paragraph)\n",
    "  3. Complete the summary table comparing SVM vs MLP accuracy\n",
    "\n",
    "**Summary Table:**\n",
    "\n",
    "| Model      | Checkerboard Test Accuracy |\n",
    "| ---------- | -------------------------- |\n",
    "| SVM (best) |                            |\n",
    "| MLP (best) |                            |\n",
    "| Difference |                            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0decdd6",
   "metadata": {},
   "source": [
    "#### Answer 1: Decision Boundary Observations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d322d5d",
   "metadata": {},
   "source": [
    "#### Answer 2: How MLP Learns the Checkerboard Pattern\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190a2dae",
   "metadata": {},
   "source": [
    "#### Answer 3: Summary Table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe3cc4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ing3513",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
